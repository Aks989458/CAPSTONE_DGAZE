{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import torch\n","from torch.utils.data import DataLoader,Dataset\n","import lightning as L\n","import pickle\n","import numpy as np\n","from tqdm import tqdm\n"],"metadata":{"id":"NcvubjUy0-_e"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"veYIZ9SIiSN9"},"outputs":[],"source":["\n","\n","class DGazeDataset(Dataset):\n","    def __init__(self, driver_data, drivers, sequences, transform=False):\n","        \"\"\"\n","        Hybrid Dataset:\n","        - Lazy loads frames (low memory usage).\n","        - Computes global normalization stats for eye images & facial features.\n","        - Normalizes gaze points to [0,1].\n","        \"\"\"\n","\n","        self.driver_data = driver_data\n","        self.drivers = drivers\n","        self.sequences = sequences\n","        self.transform = transform\n","\n","        self.index = []  # list of (driver, seq_key, frame_idx)\n","\n","        # Pre-build index list\n","        for driver in drivers:\n","            data = driver_data[driver]\n","            for seq in tqdm(sequences, desc=f\"Indexing driver {driver}\"):\n","                seq_key = f\"seq{seq}\"\n","                if seq_key in data:\n","                    num_frames = len(data[seq_key][\"left_eye\"])\n","                    for frame_idx in range(num_frames):\n","                        self.index.append((driver, seq_key, frame_idx))\n","\n","        print(f\"Lazy dataset ready! Total samples: {len(self.index)}\")\n","\n","        # === Compute global normalization stats ===\n","        print(\"Computing global stats for normalization...\")\n","        all_features = []\n","        all_pixels = []\n","\n","        for driver, seq_key, frame_idx in tqdm(self.index, desc=\"Scanning data\"):\n","            data_seq = driver_data[driver][seq_key]\n","\n","            # collect eye pixels\n","            eye_img = data_seq[\"left_eye\"][frame_idx].astype(np.float32)\n","            all_pixels.append(eye_img.reshape(-1, 3))  # flatten to (N,3)\n","\n","            # collect facial features\n","            headpose = data_seq[\"headpose_pupil\"][frame_idx, 1:].astype(np.float32)\n","            face_loc = data_seq[\"face_location\"][frame_idx].astype(np.float32)\n","            all_features.append(np.concatenate((headpose, face_loc)))\n","\n","        all_pixels = np.vstack(all_pixels)\n","        all_features = np.vstack(all_features)\n","\n","        # Eye image stats (per channel)\n","        self.eye_mean = all_pixels.mean(axis=0)\n","        self.eye_std = all_pixels.std(axis=0)\n","\n","        # Facial features stats\n","        self.feat_mean = all_features.mean(axis=0)\n","        self.feat_std = all_features.std(axis=0)\n","\n","        print(\"Normalization stats ready!\")\n","\n","    def __len__(self):\n","        return len(self.index)\n","\n","    def __getitem__(self, idx):\n","        driver, seq_key, frame_idx = self.index[idx]\n","        data_seq = self.driver_data[driver][seq_key]\n","\n","        # --- Load & normalize left eye ---\n","        left_eye = data_seq[\"left_eye\"][frame_idx].astype(np.float32)\n","        left_eye = (left_eye - self.eye_mean) / (self.eye_std + 1e-6)  # normalize\n","        left_eye = np.transpose(left_eye, (2, 0, 1))  # (C,H,W)\n","        left_eye = torch.tensor(left_eye, dtype=torch.float32)\n","\n","        # --- Load & normalize facial features ---\n","        headpose = data_seq[\"headpose_pupil\"][frame_idx, 1:].astype(np.float32)\n","        face_loc = data_seq[\"face_location\"][frame_idx].astype(np.float32)\n","        facial = np.concatenate((headpose, face_loc))\n","        facial = (facial - self.feat_mean) / (self.feat_std + 1e-6)\n","        facial_features = torch.tensor(facial, dtype=torch.float32)\n","\n","        # --- Load gaze point & normalize to [0,1] ---\n","        gaze_point = data_seq[\"gaze_point\"][frame_idx, :2].astype(np.float32).copy()\n","        gaze_point[0] = np.clip(gaze_point[0], 0, 1919) / 1920.0\n","        gaze_point[1] = np.clip(gaze_point[1], 0, 1079) / 1080.0\n","        gaze_point = torch.tensor(gaze_point, dtype=torch.float32)\n","\n","        # --- Optional transforms ---\n","        if self.transform:\n","            # Add torchvision transforms here if needed\n","            pass\n","\n","        return left_eye, facial_features, gaze_point\n"]},{"cell_type":"code","source":["\n","class DGazeDataModule(L.LightningDataModule):\n","    def __init__(self, data_path, split_path, batch_size=64, num_workers=4, transform=False):\n","        super().__init__()\n","        self.data_path = data_path\n","        self.split_path = split_path\n","        self.batch_size = batch_size\n","        self.num_workers = num_workers\n","        self.transform = transform\n","\n","        self.driver_data = None\n","        self.data_split = None\n","        self.train_dataset = None\n","        self.val_dataset = None\n","        self.test_dataset = None\n","\n","    def prepare_data(self):\n","        # Load once (not distributed)\n","        with open(self.data_path, \"rb\") as f:\n","            self.driver_data = pickle.load(f)\n","        with open(self.split_path, \"rb\") as f:\n","            self.data_split = pickle.load(f)\n","\n","    def setup(self, stage=None):\n","        # Build datasets only once\n","        if self.train_dataset is None:\n","            self.train_dataset = DGazeDataset(\n","                self.driver_data,\n","                self.data_split[\"drivers_train\"],\n","                self.data_split[\"sequence_train\"],\n","                transform=self.transform\n","            )\n","\n","        if self.val_dataset is None:\n","            self.val_dataset = DGazeDataset(\n","                self.driver_data,\n","                self.data_split[\"drivers_val\"],\n","                self.data_split[\"sequence_val\"],\n","                transform=self.transform\n","            )\n","\n","        if self.test_dataset is None:\n","            self.test_dataset = DGazeDataset(\n","                self.driver_data,\n","                self.data_split[\"drivers_test\"],\n","                self.data_split[\"sequence_test\"],\n","                transform=self.transform\n","            )\n","\n","    def train_dataloader(self):\n","        return DataLoader(self.train_dataset, batch_size=self.batch_size,\n","                          shuffle=True, num_workers=self.num_workers, pin_memory=True)\n","\n","    def val_dataloader(self):\n","        return DataLoader(self.val_dataset, batch_size=self.batch_size,\n","                          shuffle=False, num_workers=self.num_workers, pin_memory=True)\n","\n","    def test_dataloader(self):\n","        return DataLoader(self.test_dataset, batch_size=self.batch_size,\n","                          shuffle=False, num_workers=self.num_workers, pin_memory=True)\n"],"metadata":{"id":"yQzcvfgWjPu6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"2qi0ZqKP4OU1"},"execution_count":null,"outputs":[]}]}