{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"7B6tjFV8osf-"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from lightning.pytorch import LightningModule\n","from torchmetrics import Metric\n","\n","\n","# =====================================================\n","# Pixel MAE Metric (1920Ã—1080 as in DGAZE)\n","# =====================================================\n","class PixelMAE(Metric):\n","    def __init__(self, screen_w=1920, screen_h=1080):\n","        super().__init__(dist_sync_on_step=False)\n","        self.add_state(\"sum_abs_err\", default=torch.tensor(0.0), dist_reduce_fx=\"sum\")\n","        self.add_state(\"total\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n","        self.screen_w = screen_w\n","        self.screen_h = screen_h\n","\n","    def update(self, preds: torch.Tensor, target: torch.Tensor):\n","        scale = torch.tensor([self.screen_w, self.screen_h], device=preds.device)\n","        preds_px = preds * scale\n","        target_px = target * scale\n","        err = torch.abs(preds_px - target_px).sum(dim=1)  # L1 per sample\n","        self.sum_abs_err += err.sum()\n","        self.total += preds.size(0)\n","\n","    def compute(self):\n","        return self.sum_abs_err / self.total\n","\n","\n","# =====================================================\n","# SimpleEyeEncoder (for BaseGazeModel)\n","# =====================================================\n","class SimpleEyeEncoder(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n","        self.bn1 = nn.BatchNorm2d(32)\n","        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n","        self.bn2 = nn.BatchNorm2d(64)\n","        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n","        self.bn3 = nn.BatchNorm2d(128)\n","        self.pool = nn.MaxPool2d(2)\n","        self.fc = nn.Linear(128, 512)\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n","        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n","        x = F.relu(self.bn3(self.conv3(x)))\n","        x = F.adaptive_avg_pool2d(x, 1).view(x.size(0), -1)\n","        v = F.relu(self.fc(x))\n","        return v\n","\n","\n","# =====================================================\n","# Residual Dense Block (for Model1)\n","# =====================================================\n","class ResidualDenseBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels=32):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, padding=1)\n","        self.conv2 = nn.Conv2d(in_channels + out_channels, out_channels, 3, padding=1)\n","        self.conv3 = nn.Conv2d(in_channels + 2 * out_channels, out_channels, 3, padding=1)\n","        self.lff_conv = nn.Conv2d(in_channels + 3 * out_channels, out_channels, 1)\n","\n","    def forward(self, x):\n","        c1 = F.relu(self.conv1(x))\n","        c2 = F.relu(self.conv2(torch.cat([x, c1], 1)))\n","        c3 = F.relu(self.conv3(torch.cat([x, c1, c2], 1)))\n","        lff = self.lff_conv(torch.cat([x, c1, c2, c3], 1))\n","        return lff + x\n","\n","\n","# =====================================================\n","# ResDenseEyeEncoder (for Model1)\n","# =====================================================\n","class ResDenseEyeEncoder(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.initial_conv = nn.Conv2d(3, 32, 3, padding=1)\n","        self.rdbs = nn.Sequential(\n","            ResidualDenseBlock(32),\n","            ResidualDenseBlock(32),\n","            ResidualDenseBlock(32)\n","        )\n","        self.global_fusion_conv = nn.Conv2d(32 * 3, 32, 1)\n","        self.pool = nn.AdaptiveAvgPool2d(1)\n","        self.fc = nn.Linear(32, 512)\n","\n","    def forward(self, x):\n","        x = F.relu(self.initial_conv(x))\n","        rdb1 = self.rdbs[0](x)\n","        rdb2 = self.rdbs[1](rdb1)\n","        rdb3 = self.rdbs[2](rdb2)\n","        gff_input = torch.cat([rdb1, rdb2, rdb3], 1)\n","        gff_output = self.global_fusion_conv(gff_input)\n","        final_output = x + gff_output\n","        v = self.pool(final_output).view(final_output.size(0), -1)\n","        v = F.relu(self.fc(v))\n","        return v\n","\n","\n","# =====================================================\n","# Landmarks Encoder\n","# =====================================================\n","class LandmarksEncoder(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(14, 64),\n","            nn.ReLU(),\n","            nn.Linear(64, 128),\n","            nn.ReLU()\n","        )\n","\n","    def forward(self, lm):\n","        return self.net(lm)\n","\n","\n","# =====================================================\n","# Attention module\n","# =====================================================\n","class AttentionModule(nn.Module):\n","    def __init__(self, feature_dim):\n","        super().__init__()\n","        self.attention = nn.Sequential(\n","            nn.Linear(feature_dim, feature_dim),\n","            nn.ReLU(),\n","            nn.Linear(feature_dim, 1),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        w = self.attention(x)\n","        return x * w\n","\n","\n","# =====================================================\n","# BaseGazeModel (SimpleEyeEncoder + Landmarks)\n","# =====================================================\n","class BaseGazeModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.eye = SimpleEyeEncoder()\n","        self.lm = LandmarksEncoder()\n","        self.eye_attention = AttentionModule(512)\n","        self.lm_attention = AttentionModule(128)\n","        self.fusion = nn.Sequential(\n","            nn.Linear(512 + 128, 256),\n","            nn.ReLU(),\n","            nn.Dropout(0.2)\n","        )\n","        self.regressor = nn.Sequential(\n","            nn.Linear(256, 64),\n","            nn.ReLU(),\n","            nn.Linear(64, 2)\n","        )\n","\n","    def forward(self, left_eye, landmarks):\n","        v_eye = self.eye(left_eye)\n","        v_lm = self.lm(landmarks)\n","        v_eye = self.eye_attention(v_eye)\n","        v_lm = self.lm_attention(v_lm)\n","        fused = torch.cat([v_eye, v_lm], dim=1)\n","        fused = self.fusion(fused)\n","        coords = self.regressor(fused)\n","        return coords\n","\n","\n","# =====================================================\n","# Model1 (ResDenseEyeEncoder + Landmarks)\n","# =====================================================\n","class Model1(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.eye = ResDenseEyeEncoder()\n","        self.lm = LandmarksEncoder()\n","        self.eye_attention = AttentionModule(512)\n","        self.lm_attention = AttentionModule(128)\n","        self.fusion = nn.Sequential(\n","            nn.Linear(512 + 128, 256),\n","            nn.ReLU(),\n","            nn.Dropout(0.2)\n","        )\n","        self.regressor = nn.Sequential(\n","            nn.Linear(256, 64),\n","            nn.ReLU(),\n","            nn.Linear(64, 2)\n","        )\n","\n","    def forward(self, left_eye, landmarks):\n","        v_eye = self.eye(left_eye)\n","        v_lm = self.lm(landmarks)\n","        v_eye = self.eye_attention(v_eye)\n","        v_lm = self.lm_attention(v_lm)\n","        fused = torch.cat([v_eye, v_lm], dim=1)\n","        fused = self.fusion(fused)\n","        coords = self.regressor(fused)\n","        return coords\n","\n","\n","# =====================================================\n","# Shared LightningModule\n","# =====================================================\n","class _LitBase(LightningModule):\n","    def __init__(self, model, lr=1e-4, weight_decay=1e-5):\n","        super().__init__()\n","        self.model = model\n","        self.loss_fn = nn.L1Loss()\n","        self.pixel_mae_train = PixelMAE()\n","        self.pixel_mae_val = PixelMAE()\n","        self.pixel_mae_test = PixelMAE()\n","        self.lr = lr\n","        self.weight_decay = weight_decay\n","\n","    def forward(self, left_eye, landmarks):\n","        return self.model(left_eye, landmarks)\n","\n","    def training_step(self, batch, batch_idx):\n","        left_eye, landmarks, gaze_xy = batch\n","        preds = self(left_eye, landmarks)\n","        loss = self.loss_fn(preds, gaze_xy)\n","        self.pixel_mae_train.update(preds, gaze_xy)\n","        self.log(\"train/loss\", loss, on_step=False, on_epoch=True)\n","        return loss\n","\n","    def on_train_epoch_end(self):\n","        mae = self.pixel_mae_train.compute()\n","        self.log(\"train/mae_pixels\", mae, prog_bar=True)\n","        self.pixel_mae_train.reset()\n","\n","    def validation_step(self, batch, batch_idx):\n","        left_eye, landmarks, gaze_xy = batch\n","        preds = self(left_eye, landmarks)\n","        loss = self.loss_fn(preds, gaze_xy)\n","        self.pixel_mae_val.update(preds, gaze_xy)\n","        self.log(\"val/loss\", loss, prog_bar=True)\n","        return loss\n","\n","    def on_validation_epoch_end(self):\n","        mae = self.pixel_mae_val.compute()\n","        self.log(\"val/mae_pixels\", mae, prog_bar=True)\n","        self.pixel_mae_val.reset()\n","\n","    def test_step(self, batch, batch_idx):\n","        left_eye, landmarks, gaze_xy = batch\n","        preds = self(left_eye, landmarks)\n","        self.pixel_mae_test.update(preds, gaze_xy)\n","\n","    def on_test_epoch_end(self):\n","        mae = self.pixel_mae_test.compute()\n","        self.log(\"test/mae_pixels\", mae, prog_bar=True)\n","        self.pixel_mae_test.reset()\n","\n","    def configure_optimizers(self):\n","        optimizer = torch.optim.Adam(\n","            self.parameters(), lr=self.lr, weight_decay=self.weight_decay\n","        )\n","        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n","            optimizer, mode=\"min\", factor=0.1, patience=12, min_lr=1e-6\n","        )\n","        return {\n","            \"optimizer\": optimizer,\n","            \"lr_scheduler\": {\"scheduler\": scheduler, \"monitor\": \"val/loss\"},\n","        }\n","\n","\n","# =====================================================\n","# LightningModule for BaseGazeModel\n","# =====================================================\n","class LitBaseGazeModel(_LitBase):\n","    \"\"\"Lightning wrapper for BaseGazeModel\"\"\"\n","    def __init__(self, model, lr=1e-4, weight_decay=1e-5):\n","        super().__init__(model, lr, weight_decay)\n","\n","\n","# =====================================================\n","# LightningModule for Model1 (ResDenseEyeEncoder)\n","# =====================================================\n","class LitModel1(_LitBase):\n","    \"\"\"Lightning wrapper for Model1 (ResDenseEyeEncoder)\"\"\"\n","    def __init__(self, model, lr=1e-4, weight_decay=1e-5):\n","        super().__init__(model, lr, weight_decay)\n"]},{"cell_type":"code","source":[],"metadata":{"id":"yIw9sCw8pYUe"},"execution_count":null,"outputs":[]}]}