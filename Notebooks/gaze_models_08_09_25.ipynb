{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","authorship_tag":"ABX9TyPG+FAOSRYgjnR7/cv1bgj3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["pip install lightning"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MZPppNbq8Iu7","executionInfo":{"status":"ok","timestamp":1757328500539,"user_tz":-330,"elapsed":9620,"user":{"displayName":"Aniket Singh","userId":"04688736867203462514"}},"outputId":"56c5fb89-f2d1-40fa-e5df-1ecfccd4ea68"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting lightning\n","  Downloading lightning-2.5.5-py3-none-any.whl.metadata (39 kB)\n","Requirement already satisfied: PyYAML<8.0,>5.4 in /usr/local/lib/python3.12/dist-packages (from lightning) (6.0.2)\n","Requirement already satisfied: fsspec<2027.0,>=2022.5.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning) (2025.3.0)\n","Collecting lightning-utilities<2.0,>=0.10.0 (from lightning)\n","  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n","Requirement already satisfied: packaging<27.0,>=20.0 in /usr/local/lib/python3.12/dist-packages (from lightning) (25.0)\n","Requirement already satisfied: torch<4.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from lightning) (2.8.0+cu126)\n","Collecting torchmetrics<3.0,>0.7.0 (from lightning)\n","  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.12/dist-packages (from lightning) (4.67.1)\n","Requirement already satisfied: typing-extensions<6.0,>4.5.0 in /usr/local/lib/python3.12/dist-packages (from lightning) (4.15.0)\n","Collecting pytorch-lightning (from lightning)\n","  Downloading pytorch_lightning-2.5.5-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning) (3.12.15)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning) (75.2.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.19.1)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.4.0)\n","Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics<3.0,>0.7.0->lightning) (2.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (6.6.4)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.20.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<4.0,>=2.1.0->lightning) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<4.0,>=2.1.0->lightning) (3.0.2)\n","Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.12/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (3.10)\n","Downloading lightning-2.5.5-py3-none-any.whl (828 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m828.5/828.5 kB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n","Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pytorch_lightning-2.5.5-py3-none-any.whl (832 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m832.4/832.4 kB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: lightning-utilities, torchmetrics, pytorch-lightning, lightning\n","Successfully installed lightning-2.5.5 lightning-utilities-0.15.2 pytorch-lightning-2.5.5 torchmetrics-1.8.2\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"Z76qkMY675X_","executionInfo":{"status":"ok","timestamp":1757328563926,"user_tz":-330,"elapsed":36,"user":{"displayName":"Aniket Singh","userId":"04688736867203462514"}}},"outputs":[],"source":["# -*- coding: utf-8 -*-\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from lightning.pytorch import LightningModule\n","from torchmetrics import Metric\n","\n","\n","# =====================================================\n","# Pixel MAE Metric (1920×1080 as in DGAZE)\n","# =====================================================\n","class PixelMAE(Metric):\n","    def __init__(self, screen_w=1920, screen_h=1080):\n","        super().__init__(dist_sync_on_step=False)\n","        self.add_state(\"sum_abs_err\", default=torch.tensor(0.0), dist_reduce_fx=\"sum\")\n","        self.add_state(\"total\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n","        self.screen_w = screen_w\n","        self.screen_h = screen_h\n","\n","    def update(self, preds: torch.Tensor, target: torch.Tensor):\n","        scale = torch.tensor([self.screen_w, self.screen_h], device=preds.device)\n","        preds_px = preds * scale\n","        target_px = target * scale\n","        err = torch.abs(preds_px - target_px).sum(dim=1)  # L1 per sample\n","        self.sum_abs_err += err.sum()\n","        self.total += preds.size(0)\n","\n","    def compute(self):\n","        return self.sum_abs_err / self.total\n","\n","\n","# =====================================================\n","# SimpleEyeEncoder\n","# =====================================================\n","class SimpleEyeEncoder(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n","        self.bn1 = nn.BatchNorm2d(32)\n","        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n","        self.bn2 = nn.BatchNorm2d(64)\n","        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n","        self.bn3 = nn.BatchNorm2d(128)\n","        self.pool = nn.MaxPool2d(2)\n","        self.fc = nn.Linear(128, 512)\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n","        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n","        x = F.relu(self.bn3(self.conv3(x)))\n","        x = F.adaptive_avg_pool2d(x, 1).view(x.size(0), -1)\n","        v = F.relu(self.fc(x))\n","        return v\n","\n","\n","# =====================================================\n","# Residual Dense Block\n","# =====================================================\n","class ResidualDenseBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels=None):\n","        super().__init__()\n","        out_channels = out_channels or in_channels\n","        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, padding=1)\n","        self.conv2 = nn.Conv2d(in_channels + out_channels, out_channels, 3, padding=1)\n","        self.conv3 = nn.Conv2d(in_channels + 2 * out_channels, out_channels, 3, padding=1)\n","        self.lff_conv = nn.Conv2d(in_channels + 3 * out_channels, out_channels, 1)\n","\n","    def forward(self, x):\n","        c1 = F.relu(self.conv1(x))\n","        c2 = F.relu(self.conv2(torch.cat([x, c1], 1)))\n","        c3 = F.relu(self.conv3(torch.cat([x, c1, c2], 1)))\n","        lff = self.lff_conv(torch.cat([x, c1, c2, c3], 1))\n","        return lff + x\n","\n","\n","# =====================================================\n","# ResDenseEyeEncoder\n","# =====================================================\n","class ResDenseEyeEncoder(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.initial_conv = nn.Conv2d(3, 32, 3, padding=1)\n","        self.rdbs = nn.Sequential(\n","            ResidualDenseBlock(32),\n","            ResidualDenseBlock(32),\n","            ResidualDenseBlock(32)\n","        )\n","        self.global_fusion_conv = nn.Conv2d(32 * 3, 32, 1)\n","        self.pool = nn.AdaptiveAvgPool2d(1)\n","        self.fc = nn.Linear(32, 512)\n","\n","    def forward(self, x):\n","        x = F.relu(self.initial_conv(x))\n","        rdb1 = self.rdbs[0](x)\n","        rdb2 = self.rdbs[1](rdb1)\n","        rdb3 = self.rdbs[2](rdb2)\n","        gff_input = torch.cat([rdb1, rdb2, rdb3], 1)\n","        gff_output = self.global_fusion_conv(gff_input)\n","        final_output = x + gff_output\n","        v = self.pool(final_output).view(final_output.size(0), -1)\n","        v = F.relu(self.fc(v))\n","        return v\n","\n","\n","# =====================================================\n","# Landmarks Encoder\n","# =====================================================\n","class LandmarksEncoder(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(14, 64),\n","            nn.ReLU(),\n","            nn.Linear(64, 128),\n","            nn.ReLU()\n","        )\n","\n","    def forward(self, lm):\n","        return self.net(lm)\n","\n","\n","# =====================================================\n","# Attention module\n","# =====================================================\n","class AttentionModule(nn.Module):\n","    def __init__(self, feature_dim):\n","        super().__init__()\n","        self.attention = nn.Sequential(\n","            nn.Linear(feature_dim, feature_dim),\n","            nn.ReLU(),\n","            nn.Linear(feature_dim, 1),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        w = self.attention(x)\n","        return x * w\n","\n","\n","# =====================================================\n","# Gaze Model (modular with encoder)\n","# =====================================================\n","class GazeModel(nn.Module):\n","    def __init__(self, EncoderCls):\n","        super().__init__()\n","        self.eye = EncoderCls()\n","        self.lm = LandmarksEncoder()\n","        self.eye_attention = AttentionModule(512)\n","        self.lm_attention = AttentionModule(128)\n","        self.fusion = nn.Sequential(\n","            nn.Linear(512 + 128, 256),\n","            nn.ReLU(),\n","            nn.Dropout(0.2)\n","        )\n","        self.regressor = nn.Sequential(\n","            nn.Linear(256, 64),\n","            nn.ReLU(),\n","            nn.Linear(64, 2)\n","        )\n","\n","    def forward(self, left_eye, landmarks):\n","        v_eye = self.eye(left_eye)\n","        v_lm = self.lm(landmarks)\n","        v_eye = self.eye_attention(v_eye)\n","        v_lm = self.lm_attention(v_lm)\n","        fused = torch.cat([v_eye, v_lm], dim=1)\n","        fused = self.fusion(fused)\n","        coords = self.regressor(fused)\n","        return coords\n","\n","\n","# =====================================================\n","# Shared LightningModule\n","# =====================================================\n","class LitBase(LightningModule):\n","    def __init__(self,\n","                 model,\n","                 lr=1e-4,\n","                 weight_decay=1e-5,\n","                 loss_fn=nn.L1Loss(),\n","                 pixel_mae_train=PixelMAE(),\n","                 pixel_mae_val=PixelMAE(),\n","                 pixel_mae_test=PixelMAE(),\n","                 ):\n","        super().__init__()\n","        self.model           = model\n","        self.lr              = lr\n","        self.weight_decay    = weight_decay\n","        self.loss_fn         = loss_fn\n","        self.pixel_mae_train = pixel_mae_train\n","        self.pixel_mae_val   = pixel_mae_val\n","        self.pixel_mae_test  = pixel_mae_test\n","\n","    def forward(self, left_eye, landmarks):\n","        return self.model(left_eye, landmarks)\n","\n","    def training_step(self, batch, batch_idx):\n","        left_eye, landmarks, gaze_xy = batch\n","        preds = self(left_eye, landmarks)\n","        loss = self.loss_fn(preds, gaze_xy)\n","        self.pixel_mae_train.update(preds, gaze_xy)\n","        self.log(\"train/loss\", loss, on_step=False, on_epoch=True)\n","        return loss\n","\n","    def on_train_epoch_end(self):\n","        mae = self.pixel_mae_train.compute()\n","        self.log(\"train/mae_pixels\", mae, prog_bar=True)\n","        self.pixel_mae_train.reset()\n","\n","    def validation_step(self, batch, batch_idx):\n","        left_eye, landmarks, gaze_xy = batch\n","        preds = self(left_eye, landmarks)\n","        loss = self.loss_fn(preds, gaze_xy)\n","        self.pixel_mae_val.update(preds, gaze_xy)\n","        self.log(\"val/loss\", loss, prog_bar=True)\n","        return loss\n","\n","    def on_validation_epoch_end(self):\n","        mae = self.pixel_mae_val.compute()\n","        self.log(\"val/mae_pixels\", mae, prog_bar=True)\n","        self.pixel_mae_val.reset()\n","\n","    def test_step(self, batch, batch_idx):\n","        left_eye, landmarks, gaze_xy = batch\n","        preds = self(left_eye, landmarks)\n","        self.pixel_mae_test.update(preds, gaze_xy)\n","\n","    def on_test_epoch_end(self):\n","        mae = self.pixel_mae_test.compute()\n","        self.log(\"test/mae_pixels\", mae, prog_bar=True)\n","        self.pixel_mae_test.reset()\n","\n","    def configure_optimizers(self):\n","        optimizer = torch.optim.Adam(\n","            self.parameters(), lr=self.lr, weight_decay=self.weight_decay\n","        )\n","        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n","            optimizer, mode=\"min\", factor=0.1, patience=12, min_lr=1e-6\n","        )\n","        return {\n","            \"optimizer\": optimizer,\n","            \"lr_scheduler\": {\"scheduler\": scheduler, \"monitor\": \"val/loss\"},\n","        }\n","\n","\n","# =====================================================\n","# Convenience Wrappers\n","# =====================================================\n","class SimpleLitModel(LitBase):\n","    def __init__(self, *args, **kwargs):\n","        super().__init__(GazeModel(SimpleEyeEncoder), *args, **kwargs)\n","\n","\n","class ResDenseLitModel(LitBase):\n","    def __init__(self, *args, **kwargs):\n","        super().__init__(GazeModel(ResDenseEyeEncoder), *args, **kwargs)\n"]},{"cell_type":"code","source":[],"metadata":{"id":"g_v5wzGH8OnS"},"execution_count":null,"outputs":[]}]}